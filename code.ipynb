{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":216202315,"sourceType":"kernelVersion"}],"dockerImageVersionId":30823,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":96.791585,"end_time":"2024-06-06T14:07:00.519058","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-06-06T14:05:23.727473","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RSNA 2024 Lumbar Spine Degenerative Classification","metadata":{"papermill":{"duration":0.017073,"end_time":"2024-06-06T14:05:26.440244","exception":false,"start_time":"2024-06-06T14:05:26.423171","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Starter Notebook for Pytorch and Deep learning techniques\n\nUsing ResNET","metadata":{"papermill":{"duration":0.016328,"end_time":"2024-06-06T14:05:26.473098","exception":false,"start_time":"2024-06-06T14:05:26.45677","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"What does this notebook contains?\n\n* Data organized in an understandable and easy to use way\n* A pretrained ResNET for inference\n\nI have tried creating a notebook where you can just plug your deep learning models and everything else is sorted. ","metadata":{"papermill":{"duration":0.017113,"end_time":"2024-06-06T14:05:26.506431","exception":false,"start_time":"2024-06-06T14:05:26.489318","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import seaborn as sns\n\nimport matplotlib.pyplot as plt\nimport os\nimport time\nimport numpy as np\nimport glob\nimport json\nimport collections\nimport torch\nimport torch.nn as nn\n\nimport pydicom as dicom\nimport matplotlib.patches as patches\n\nfrom matplotlib import animation, rc\nimport pandas as pd\n\nimport pydicom as dicom # dicom\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:38.976679Z","iopub.execute_input":"2025-01-05T13:04:38.977011Z","iopub.status.idle":"2025-01-05T13:04:38.982124Z","shell.execute_reply.started":"2025-01-05T13:04:38.976987Z","shell.execute_reply":"2025-01-05T13:04:38.981285Z"},"papermill":{"duration":5.5507,"end_time":"2024-06-06T14:05:32.073477","exception":false,"start_time":"2024-06-06T14:05:26.522777","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# read data\ntrain_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/'\n\ntrain  = pd.read_csv(train_path + 'train.csv')\nlabel = pd.read_csv(train_path + 'train_label_coordinates.csv')\ntrain_desc  = pd.read_csv(train_path + 'train_series_descriptions.csv')\ntest_desc   = pd.read_csv(train_path + 'test_series_descriptions.csv')\nsub         = pd.read_csv(train_path + 'sample_submission.csv')\nfake_test_data = False # len(sub) <= 25 # For testing purposes replace False with commented value","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:38.983248Z","iopub.execute_input":"2025-01-05T13:04:38.983508Z","iopub.status.idle":"2025-01-05T13:04:39.082994Z","shell.execute_reply.started":"2025-01-05T13:04:38.983478Z","shell.execute_reply":"2025-01-05T13:04:39.08229Z"},"papermill":{"duration":0.185667,"end_time":"2024-06-06T14:05:32.276032","exception":false,"start_time":"2024-06-06T14:05:32.090365","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if fake_test_data:\n    # Create Fake Test data\n    n = 100\n    selected_studies = pd.Series(train_desc.study_id.unique()).sample(n).values\n    test_desc = train_desc[train_desc.study_id.isin(selected_studies)]\n    print(f\"New test_desc length: {len(test_desc)}\")\n\n    # Get 25 formats from current sub DataFrame\n    row_label_formats = [(\"{}_\" + row_id.split(\"_\", 1)[1]) for row_id in sub.row_id.tolist()]\n\n    row_ids = [\n        row_format.format(study)\n        for study in selected_studies for row_format in row_label_formats\n    ]\n    sub = pd.DataFrame(dict(row_id=row_ids, normal_mild=1/3, moderate=1/3, severe=1/3))\n    print(f\"New sub length: {len(sub)}\")","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:39.084475Z","iopub.execute_input":"2025-01-05T13:04:39.084693Z","iopub.status.idle":"2025-01-05T13:04:39.089794Z","shell.execute_reply.started":"2025-01-05T13:04:39.084675Z","shell.execute_reply":"2025-01-05T13:04:39.08887Z"},"papermill":{"duration":0.026124,"end_time":"2024-06-06T14:05:32.319522","exception":false,"start_time":"2024-06-06T14:05:32.293398","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_desc.head(5)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:39.091203Z","iopub.execute_input":"2025-01-05T13:04:39.091538Z","iopub.status.idle":"2025-01-05T13:04:39.10716Z","shell.execute_reply.started":"2025-01-05T13:04:39.091516Z","shell.execute_reply":"2025-01-05T13:04:39.106484Z"},"papermill":{"duration":0.036782,"end_time":"2024-06-06T14:05:32.372704","exception":false,"start_time":"2024-06-06T14:05:32.335922","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:39.108008Z","iopub.execute_input":"2025-01-05T13:04:39.108284Z","iopub.status.idle":"2025-01-05T13:04:39.129861Z","shell.execute_reply.started":"2025-01-05T13:04:39.108256Z","shell.execute_reply":"2025-01-05T13:04:39.129148Z"},"papermill":{"duration":0.044872,"end_time":"2024-06-06T14:05:32.434098","exception":false,"start_time":"2024-06-06T14:05:32.389226","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_desc.head(5)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:39.130647Z","iopub.execute_input":"2025-01-05T13:04:39.130921Z","iopub.status.idle":"2025-01-05T13:04:39.147895Z","shell.execute_reply.started":"2025-01-05T13:04:39.130893Z","shell.execute_reply":"2025-01-05T13:04:39.146981Z"},"papermill":{"duration":0.028301,"end_time":"2024-06-06T14:05:32.479534","exception":false,"start_time":"2024-06-06T14:05:32.451233","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to generate image paths based on directory structure\ndef generate_image_paths(df, data_dir):\n    image_paths = []\n    for study_id, series_id in zip(df['study_id'], df['series_id']):\n        study_dir = os.path.join(data_dir, str(study_id))\n        series_dir = os.path.join(study_dir, str(series_id))\n        images = os.listdir(series_dir)\n        image_paths.extend([os.path.join(series_dir, img) for img in images])\n    return image_paths\n\n# Generate image paths for train and test data\ntrain_image_paths = generate_image_paths(train_desc, '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images')\ntest_image_paths = generate_image_paths(test_desc, f'/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/{\"train_images\" if fake_test_data else \"test_images\"}')","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:39.148811Z","iopub.execute_input":"2025-01-05T13:04:39.149087Z","iopub.status.idle":"2025-01-05T13:04:42.939337Z","shell.execute_reply.started":"2025-01-05T13:04:39.149067Z","shell.execute_reply":"2025-01-05T13:04:42.938667Z"},"papermill":{"duration":47.093749,"end_time":"2024-06-06T14:06:19.590943","exception":false,"start_time":"2024-06-06T14:05:32.497194","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_desc)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:42.941824Z","iopub.execute_input":"2025-01-05T13:04:42.942051Z","iopub.status.idle":"2025-01-05T13:04:42.94651Z","shell.execute_reply.started":"2025-01-05T13:04:42.942031Z","shell.execute_reply":"2025-01-05T13:04:42.945814Z"},"papermill":{"duration":0.026497,"end_time":"2024-06-06T14:06:19.63653","exception":false,"start_time":"2024-06-06T14:06:19.610033","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_image_paths)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:42.947826Z","iopub.execute_input":"2025-01-05T13:04:42.948116Z","iopub.status.idle":"2025-01-05T13:04:42.961745Z","shell.execute_reply.started":"2025-01-05T13:04:42.948091Z","shell.execute_reply":"2025-01-05T13:04:42.961067Z"},"papermill":{"duration":0.02564,"end_time":"2024-06-06T14:06:19.679604","exception":false,"start_time":"2024-06-06T14:06:19.653964","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pydicom\nimport matplotlib.pyplot as plt\n\n# Function to open and display DICOM images\ndef display_dicom_images(image_paths):\n    plt.figure(figsize=(15, 5))  # Adjust figure size if needed\n    for i, path in enumerate(image_paths[:3]):\n        ds = pydicom.dcmread(path)\n        plt.subplot(1, 3, i+1)\n        plt.imshow(ds.pixel_array, cmap=plt.cm.bone)\n        plt.title(f\"Image {i+1}\")\n        plt.axis('off')\n    plt.show()\n\n# Display the first three DICOM images\ndisplay_dicom_images(train_image_paths)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:42.96241Z","iopub.execute_input":"2025-01-05T13:04:42.962683Z","iopub.status.idle":"2025-01-05T13:04:43.391141Z","shell.execute_reply.started":"2025-01-05T13:04:42.962663Z","shell.execute_reply":"2025-01-05T13:04:43.390296Z"},"papermill":{"duration":0.68945,"end_time":"2024-06-06T14:06:20.386474","exception":false,"start_time":"2024-06-06T14:06:19.697024","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pydicom\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Function to open and display DICOM images along with coordinates\ndef display_dicom_with_coordinates(image_paths, label_df):\n    fig, axs = plt.subplots(1, len(image_paths), figsize=(18, 6))\n    \n    for idx, path in enumerate(image_paths):  # Display images\n        study_id = int(path.split('/')[-3])\n        series_id = int(path.split('/')[-2])\n        \n        # Filter label coordinates for the current study and series\n        filtered_labels = label_df[(label_df['study_id'] == study_id) & (label_df['series_id'] == series_id)]\n        \n        # Read DICOM image\n        ds = pydicom.dcmread(path)\n        \n        # Plot DICOM image\n        axs[idx].imshow(ds.pixel_array, cmap='gray')\n        axs[idx].set_title(f\"Study ID: {study_id}, Series ID: {series_id}\")\n        axs[idx].axis('off')\n        \n        # Plot coordinates\n        for _, row in filtered_labels.iterrows():\n            axs[idx].plot(row['x'], row['y'], 'ro', markersize=5)\n        \n    plt.tight_layout()\n    plt.show()\n\n# Load DICOM files from a folder\ndef load_dicom_files(path_to_folder):\n    files = [os.path.join(path_to_folder, f) for f in os.listdir(path_to_folder) if f.endswith('.dcm')]\n    files.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('-')[-1]))\n    return files\n\n# Display DICOM images with coordinates\nstudy_id = \"100206310\"\nstudy_folder = f\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/{study_id}\"\n\nimage_paths = []\nfor series_folder in os.listdir(study_folder):\n    series_folder_path = os.path.join(study_folder, series_folder)\n    dicom_files = load_dicom_files(series_folder_path)\n    if dicom_files:\n        image_paths.append(dicom_files[0])  # Add the first image from each series\n\n\ndisplay_dicom_with_coordinates(image_paths, label)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:43.392177Z","iopub.execute_input":"2025-01-05T13:04:43.392547Z","iopub.status.idle":"2025-01-05T13:04:44.030512Z","shell.execute_reply.started":"2025-01-05T13:04:43.392517Z","shell.execute_reply":"2025-01-05T13:04:44.029577Z"},"papermill":{"duration":0.915994,"end_time":"2024-06-06T14:06:21.325763","exception":false,"start_time":"2024-06-06T14:06:20.409769","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{"papermill":{"duration":0.03215,"end_time":"2024-06-06T14:06:21.390895","exception":false,"start_time":"2024-06-06T14:06:21.358745","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define function to reshape a single row of the DataFrame\ndef reshape_row(row):\n    data = {'study_id': [], 'condition': [], 'level': [], 'severity': []}\n    \n    for column, value in row.items():\n        if column not in ['study_id', 'series_id', 'instance_number', 'x', 'y', 'series_description']:\n            parts = column.split('_')\n            condition = ' '.join([word.capitalize() for word in parts[:-2]])\n            level = parts[-2].capitalize() + '/' + parts[-1].capitalize()\n            data['study_id'].append(row['study_id'])\n            data['condition'].append(condition)\n            data['level'].append(level)\n            data['severity'].append(value)\n    \n    return pd.DataFrame(data)\n\n# Reshape the DataFrame for all rows\nnew_train_df = pd.concat([reshape_row(row) for _, row in train.iterrows()], ignore_index=True)\n\n# Display the first few rows of the reshaped dataframe\nnew_train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:44.031516Z","iopub.execute_input":"2025-01-05T13:04:44.031916Z","iopub.status.idle":"2025-01-05T13:04:45.033714Z","shell.execute_reply.started":"2025-01-05T13:04:44.031875Z","shell.execute_reply":"2025-01-05T13:04:45.032867Z"},"papermill":{"duration":1.444603,"end_time":"2024-06-06T14:06:22.868255","exception":false,"start_time":"2024-06-06T14:06:21.423652","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print columns in a neat way\nprint(\"\\nColumns in new_train_df:\")\nprint(\",\".join(new_train_df.columns))\n\nprint(\"\\nColumns in label:\")\nprint(\",\".join(label.columns))\n\nprint(\"\\nColumns in test_desc:\")\nprint(\",\".join(test_desc.columns))\n\nprint(\"\\nColumns in sub:\")\nprint(\",\".join(sub.columns))","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.034434Z","iopub.execute_input":"2025-01-05T13:04:45.034691Z","iopub.status.idle":"2025-01-05T13:04:45.041338Z","shell.execute_reply.started":"2025-01-05T13:04:45.034672Z","shell.execute_reply":"2025-01-05T13:04:45.040617Z"},"papermill":{"duration":0.041306,"end_time":"2024-06-06T14:06:22.94339","exception":false,"start_time":"2024-06-06T14:06:22.902084","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Merge the dataframes on the common columns\nmerged_df = pd.merge(new_train_df, label, on=['study_id', 'condition', 'level'], how='inner')\n# Merge the dataframes on the common column 'series_id'\nfinal_merged_df = pd.merge(merged_df, train_desc, on='series_id', how='inner')","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.042114Z","iopub.execute_input":"2025-01-05T13:04:45.042433Z","iopub.status.idle":"2025-01-05T13:04:45.095017Z","shell.execute_reply.started":"2025-01-05T13:04:45.042404Z","shell.execute_reply":"2025-01-05T13:04:45.094335Z"},"papermill":{"duration":0.113614,"end_time":"2024-06-06T14:06:23.089562","exception":false,"start_time":"2024-06-06T14:06:22.975948","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Merge the dataframes on the common column 'series_id'\nfinal_merged_df = pd.merge(merged_df, train_desc, on=['series_id','study_id'], how='inner')\n# Display the first few rows of the final merged dataframe\nfinal_merged_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.095754Z","iopub.execute_input":"2025-01-05T13:04:45.095941Z","iopub.status.idle":"2025-01-05T13:04:45.116893Z","shell.execute_reply.started":"2025-01-05T13:04:45.095925Z","shell.execute_reply":"2025-01-05T13:04:45.116191Z"},"papermill":{"duration":0.063629,"end_time":"2024-06-06T14:06:23.18908","exception":false,"start_time":"2024-06-06T14:06:23.125451","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_merged_df[final_merged_df['study_id'] == 100206310].sort_values(['x','y'],ascending = True)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.117604Z","iopub.execute_input":"2025-01-05T13:04:45.117804Z","iopub.status.idle":"2025-01-05T13:04:45.132569Z","shell.execute_reply.started":"2025-01-05T13:04:45.117787Z","shell.execute_reply":"2025-01-05T13:04:45.131932Z"},"papermill":{"duration":0.058239,"end_time":"2024-06-06T14:06:23.280211","exception":false,"start_time":"2024-06-06T14:06:23.221972","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_merged_df[final_merged_df['series_id'] == 1012284084].sort_values(\"instance_number\")","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.133278Z","iopub.execute_input":"2025-01-05T13:04:45.133593Z","iopub.status.idle":"2025-01-05T13:04:45.145555Z","shell.execute_reply.started":"2025-01-05T13:04:45.133564Z","shell.execute_reply":"2025-01-05T13:04:45.144537Z"},"papermill":{"duration":0.053082,"end_time":"2024-06-06T14:06:23.367584","exception":false,"start_time":"2024-06-06T14:06:23.314502","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, we can see what the data represents\n\nSeries ID 1012284084 contains 60 images, and how each image maps to each level and condition","metadata":{"papermill":{"duration":0.034218,"end_time":"2024-06-06T14:06:23.477225","exception":false,"start_time":"2024-06-06T14:06:23.443007","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Filter the dataframe for the given study_id and sort by instance_number\nfiltered_df = final_merged_df[final_merged_df['study_id'] == 1013589491].sort_values(\"instance_number\")\n\n# Display the resulting dataframe\nfiltered_df","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.146414Z","iopub.execute_input":"2025-01-05T13:04:45.14675Z","iopub.status.idle":"2025-01-05T13:04:45.165557Z","shell.execute_reply.started":"2025-01-05T13:04:45.146722Z","shell.execute_reply":"2025-01-05T13:04:45.164745Z"},"papermill":{"duration":0.057652,"end_time":"2024-06-06T14:06:23.569421","exception":false,"start_time":"2024-06-06T14:06:23.511769","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sort final_merged_df by study_id, series_id, and series_description\nsorted_final_merged_df = final_merged_df[final_merged_df['study_id'] == 1013589491].sort_values(by=['series_id', 'series_description', 'instance_number'])\nsorted_final_merged_df","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.166402Z","iopub.execute_input":"2025-01-05T13:04:45.166695Z","iopub.status.idle":"2025-01-05T13:04:45.190009Z","shell.execute_reply.started":"2025-01-05T13:04:45.166667Z","shell.execute_reply":"2025-01-05T13:04:45.189368Z"},"papermill":{"duration":0.061241,"end_time":"2024-06-06T14:06:23.66609","exception":false,"start_time":"2024-06-06T14:06:23.604849","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We see that, <br>\nSaggital T1 images map to Neural Foraminal Narrowing <br>\nAxial T2 images map to Subarticular Stenosis <br>\nSaggital T2/STIR map to Canal Stenosis <br>","metadata":{"papermill":{"duration":0.0369,"end_time":"2024-06-06T14:06:23.739234","exception":false,"start_time":"2024-06-06T14:06:23.702334","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\n\n# Create the row_id column\nfinal_merged_df['row_id'] = (\n    final_merged_df['study_id'].astype(str) + '_' +\n    final_merged_df['condition'].str.lower().str.replace(' ', '_') + '_' +\n    final_merged_df['level'].str.lower().str.replace('/', '_')\n)\n\n# Create the image_path column\nfinal_merged_df['image_path'] = (\n    '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/' + \n    final_merged_df['study_id'].astype(str) + '/' +\n    final_merged_df['series_id'].astype(str) + '/' +\n    final_merged_df['instance_number'].astype(str) + '.dcm'\n)\n\n# Note: Check image path, since there's 1 instance id, for 1 image, but there's many more images other than the ones labelled in the instance ID. \n\n# Display the updated dataframe\nfinal_merged_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.190832Z","iopub.execute_input":"2025-01-05T13:04:45.191039Z","iopub.status.idle":"2025-01-05T13:04:45.378581Z","shell.execute_reply.started":"2025-01-05T13:04:45.191022Z","shell.execute_reply":"2025-01-05T13:04:45.377738Z"},"papermill":{"duration":0.274954,"end_time":"2024-06-06T14:06:24.051359","exception":false,"start_time":"2024-06-06T14:06:23.776405","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_merged_df[final_merged_df[\"severity\"] == \"Normal/Mild\"].value_counts().sum()","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.379265Z","iopub.execute_input":"2025-01-05T13:04:45.379504Z","iopub.status.idle":"2025-01-05T13:04:45.47903Z","shell.execute_reply.started":"2025-01-05T13:04:45.379484Z","shell.execute_reply":"2025-01-05T13:04:45.478237Z"},"papermill":{"duration":0.199922,"end_time":"2024-06-06T14:06:24.290132","exception":false,"start_time":"2024-06-06T14:06:24.09021","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_merged_df[final_merged_df[\"severity\"] == \"Moderate\"].value_counts().sum()","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.479807Z","iopub.execute_input":"2025-01-05T13:04:45.480124Z","iopub.status.idle":"2025-01-05T13:04:45.513765Z","shell.execute_reply.started":"2025-01-05T13:04:45.480093Z","shell.execute_reply":"2025-01-05T13:04:45.512999Z"},"papermill":{"duration":0.090356,"end_time":"2024-06-06T14:06:24.417683","exception":false,"start_time":"2024-06-06T14:06:24.327327","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the base path for test images\nbase_path = f'/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/{\"train_images\" if fake_test_data else \"test_images\"}'\n\n# Function to get image paths for a series\ndef get_image_paths(row):\n    series_path = os.path.join(base_path, str(row['study_id']), str(row['series_id']))\n    if os.path.exists(series_path):\n        return [os.path.join(series_path, f) for f in os.listdir(series_path) if os.path.isfile(os.path.join(series_path, f))]\n    return []\n\n# Mapping of series_description to conditions\ncondition_mapping = {\n    'Sagittal T1': {'left': 'left_neural_foraminal_narrowing', 'right': 'right_neural_foraminal_narrowing'},\n    'Axial T2': {'left': 'left_subarticular_stenosis', 'right': 'right_subarticular_stenosis'},\n    'Sagittal T2/STIR': 'spinal_canal_stenosis'\n}\n\n# Create a list to store the expanded rows\nexpanded_rows = []\n\n# Expand the dataframe by adding new rows for each file path\nfor index, row in test_desc.iterrows():\n    image_paths = get_image_paths(row)\n    conditions = condition_mapping.get(row['series_description'], {})\n    if isinstance(conditions, str):  # Single condition\n        conditions = {'left': conditions, 'right': conditions}\n    for side, condition in conditions.items():\n        for image_path in image_paths:\n            expanded_rows.append({\n                'study_id': row['study_id'],\n                'series_id': row['series_id'],\n                'series_description': row['series_description'],\n                'image_path': image_path,\n                'condition': condition,\n                'row_id': f\"{row['study_id']}_{condition}\"\n            })\n\n# Create a new dataframe from the expanded rows\nexpanded_test_desc = pd.DataFrame(expanded_rows)\n\n# Display the resulting dataframe\nexpanded_test_desc.head(5)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.517988Z","iopub.execute_input":"2025-01-05T13:04:45.518201Z","iopub.status.idle":"2025-01-05T13:04:45.575241Z","shell.execute_reply.started":"2025-01-05T13:04:45.518183Z","shell.execute_reply":"2025-01-05T13:04:45.57459Z"},"papermill":{"duration":0.108409,"end_time":"2024-06-06T14:06:24.563083","exception":false,"start_time":"2024-06-06T14:06:24.454674","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# change severity column labels\n#Normal/Mild': 'normal_mild', 'Moderate': 'moderate', 'Severe': 'severe'}\nfinal_merged_df['severity'] = final_merged_df['severity'].map({'Normal/Mild': 'normal_mild', 'Moderate': 'moderate', 'Severe': 'severe'})","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.57678Z","iopub.execute_input":"2025-01-05T13:04:45.577002Z","iopub.status.idle":"2025-01-05T13:04:45.584367Z","shell.execute_reply.started":"2025-01-05T13:04:45.576985Z","shell.execute_reply":"2025-01-05T13:04:45.58362Z"},"papermill":{"duration":0.055125,"end_time":"2024-06-06T14:06:24.657356","exception":false,"start_time":"2024-06-06T14:06:24.602231","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = expanded_test_desc\ntrain_data = final_merged_df","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.585163Z","iopub.execute_input":"2025-01-05T13:04:45.58545Z","iopub.status.idle":"2025-01-05T13:04:45.599484Z","shell.execute_reply.started":"2025-01-05T13:04:45.585429Z","shell.execute_reply":"2025-01-05T13:04:45.598718Z"},"papermill":{"duration":0.04645,"end_time":"2024-06-06T14:06:24.742202","exception":false,"start_time":"2024-06-06T14:06:24.695752","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Define a function to check if a path exists\ndef check_exists(path):\n    return os.path.exists(path)\n\n# Define a function to check if a study ID directory exists\ndef check_study_id(row):\n    study_id = row['study_id']\n    path = f'/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/{study_id}'\n    return check_exists(path)\n\n# Define a function to check if a series ID directory exists\ndef check_series_id(row):\n    study_id = row['study_id']\n    series_id = row['series_id']\n    path = f'/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/{study_id}/{series_id}'\n    return check_exists(path)\n\n# Define a function to check if an image file exists\ndef check_image_exists(row):\n    image_path = row['image_path']\n    return check_exists(image_path)\n\n# Apply the functions to the train_data dataframe\ntrain_data['study_id_exists'] = train_data.apply(check_study_id, axis=1)\ntrain_data['series_id_exists'] = train_data.apply(check_series_id, axis=1)\ntrain_data['image_exists'] = train_data.apply(check_image_exists, axis=1)\n\n# Filter train_data\ntrain_data = train_data[(train_data['study_id_exists']) & (train_data['series_id_exists']) & (train_data['image_exists'])]","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:04:45.600409Z","iopub.execute_input":"2025-01-05T13:04:45.600698Z","iopub.status.idle":"2025-01-05T13:05:02.943452Z","shell.execute_reply.started":"2025-01-05T13:04:45.600671Z","shell.execute_reply":"2025-01-05T13:05:02.942754Z"},"papermill":{"duration":15.937593,"end_time":"2024-06-06T14:06:40.718432","exception":false,"start_time":"2024-06-06T14:06:24.780839","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:06:43.745891Z","iopub.execute_input":"2025-01-05T13:06:43.746181Z","iopub.status.idle":"2025-01-05T13:06:43.759148Z","shell.execute_reply.started":"2025-01-05T13:06:43.746162Z","shell.execute_reply":"2025-01-05T13:06:43.75822Z"},"papermill":{"duration":0.057383,"end_time":"2024-06-06T14:06:40.813977","exception":false,"start_time":"2024-06-06T14:06:40.756594","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pydicom\ndef load_dicom(path):\n    dicom = pydicom.dcmread(path)\n    data = dicom.pixel_array\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:11:05.676119Z","iopub.execute_input":"2025-01-05T13:11:05.67645Z","iopub.status.idle":"2025-01-05T13:11:05.681168Z","shell.execute_reply.started":"2025-01-05T13:11:05.676426Z","shell.execute_reply":"2025-01-05T13:11:05.680268Z"},"papermill":{"duration":0.045067,"end_time":"2024-06-06T14:06:40.896404","exception":false,"start_time":"2024-06-06T14:06:40.851337","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load images randomly\nimport random\nimages = []\nrow_ids = []\nselected_indices = random.sample(range(len(train_data)), 2)\nfor i in selected_indices:\n    image = load_dicom(train_data['image_path'][i])\n    images.append(image)\n    row_ids.append(train_data['row_id'][i])\n\n# Plot images\nfig, ax = plt.subplots(1, 2, figsize=(8, 4))\nfor i in range(2):\n    ax[i].imshow(images[i], cmap='gray')\n    ax[i].set_title(f'Row ID: {row_ids[i]}', fontsize=8)\n    ax[i].axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:11:08.742219Z","iopub.execute_input":"2025-01-05T13:11:08.742589Z","iopub.status.idle":"2025-01-05T13:11:09.132509Z","shell.execute_reply.started":"2025-01-05T13:11:08.742562Z","shell.execute_reply":"2025-01-05T13:11:09.131551Z"},"papermill":{"duration":0.471952,"end_time":"2024-06-06T14:06:41.405994","exception":false,"start_time":"2024-06-06T14:06:40.934042","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading data","metadata":{"papermill":{"duration":0.039845,"end_time":"2024-06-06T14:06:41.487295","exception":false,"start_time":"2024-06-06T14:06:41.44745","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#for one hot encoding\n#train_data[['normal_mild', 'severe', 'moderate']] = train_data[['normal_mild', 'severe', 'moderate']].astype(int)  ","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:11:12.791336Z","iopub.execute_input":"2025-01-05T13:11:12.791777Z","iopub.status.idle":"2025-01-05T13:11:12.796005Z","shell.execute_reply.started":"2025-01-05T13:11:12.79174Z","shell.execute_reply":"2025-01-05T13:11:12.79479Z"},"papermill":{"duration":0.046731,"end_time":"2024-06-06T14:06:41.574013","exception":false,"start_time":"2024-06-06T14:06:41.527282","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:11:15.539122Z","iopub.execute_input":"2025-01-05T13:11:15.539456Z","iopub.status.idle":"2025-01-05T13:11:15.555217Z","shell.execute_reply.started":"2025-01-05T13:11:15.539431Z","shell.execute_reply":"2025-01-05T13:11:15.554459Z"},"papermill":{"duration":0.065233,"end_time":"2024-06-06T14:06:41.679255","exception":false,"start_time":"2024-06-06T14:06:41.614022","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = train_data.dropna()","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:11:21.092626Z","iopub.execute_input":"2025-01-05T13:11:21.092903Z","iopub.status.idle":"2025-01-05T13:11:21.119343Z","shell.execute_reply.started":"2025-01-05T13:11:21.092883Z","shell.execute_reply":"2025-01-05T13:11:21.118564Z"},"papermill":{"duration":0.082757,"end_time":"2024-06-06T14:06:41.802337","exception":false,"start_time":"2024-06-06T14:06:41.71958","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torch\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom tqdm import tqdm\n\n# Define a custom dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        image_path = self.dataframe['image_path'][index]\n        image = load_dicom(image_path)  # Define this function to load your DICOM images\n        label = self.dataframe['severity'][index]\n        \n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n# Function to create datasets and dataloaders for each series description\ndef create_datasets_and_loaders(df, series_description, transform, batch_size=8):\n    filtered_df = df[df['series_description'] == series_description]\n    \n    train_df, val_df = train_test_split(filtered_df, test_size=0.2, random_state=42)\n    train_df = train_df.reset_index(drop=True)\n    val_df = val_df.reset_index(drop=True)\n\n    train_dataset = CustomDataset(train_df, transform)\n    val_dataset = CustomDataset(val_df, transform)\n\n    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    \n    return trainloader, valloader, len(train_df), len(val_df)\n\n# Define the transforms\ntransform = transforms.Compose([\n    transforms.Lambda(lambda x: (x * 255).astype(np.uint8)),  # Convert back to uint8 for PIL\n    transforms.ToPILImage(),\n    transforms.Resize((224, 224)),\n    transforms.Grayscale(num_output_channels=3),\n    transforms.ToTensor(),\n])\n\n# Create dataloaders for each series description\ndataloaders = {}\nlengths = {}\n\ntrainloader_t1, valloader_t1, len_train_t1, len_val_t1 = create_datasets_and_loaders(train_data, 'Sagittal T1', transform)\ntrainloader_t2, valloader_t2, len_train_t2, len_val_t2 = create_datasets_and_loaders(train_data, 'Axial T2', transform)\ntrainloader_t2stir, valloader_t2stir, len_train_t2stir, len_val_t2stir = create_datasets_and_loaders(train_data, 'Sagittal T2/STIR', transform)\n\ndataloaders['Sagittal T1'] = (trainloader_t1, valloader_t1)\ndataloaders['Axial T2'] = (trainloader_t2, valloader_t2)\ndataloaders['Sagittal T2/STIR'] = (trainloader_t2stir, valloader_t2stir)\n\nlengths['Sagittal T1'] = (len_train_t1, len_val_t1)\nlengths['Axial T2'] = (len_train_t2, len_val_t2)\nlengths['Sagittal T2/STIR'] = (len_train_t2stir, len_val_t2stir)\n\n# Dictionary mapping labels to indices\nlabel_map = {'Mild': 0, 'Moderate': 1, 'Severe': 2}","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:11:23.782151Z","iopub.execute_input":"2025-01-05T13:11:23.782484Z","iopub.status.idle":"2025-01-05T13:11:25.051018Z","shell.execute_reply.started":"2025-01-05T13:11:23.782455Z","shell.execute_reply":"2025-01-05T13:11:25.050119Z"},"papermill":{"duration":1.592769,"end_time":"2024-06-06T14:06:43.436775","exception":false,"start_time":"2024-06-06T14:06:41.844006","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Function to visualize a batch of images\ndef visualize_batch(dataloader):\n    images, labels = next(iter(dataloader))\n    fig, axes = plt.subplots(1, len(images), figsize=(20, 5))\n    for i, (img, lbl) in enumerate(zip(images, labels)):\n        ax = axes[i]\n        img = img.permute(1, 2, 0)  # Convert to HWC for visualization\n        ax.imshow(img)\n        ax.set_title(f\"Label: {lbl}\")\n        ax.axis('off')\n    plt.show()\n\n# Visualize samples from each dataloader\nprint(\"Visualizing Sagittal T1 samples\")\nvisualize_batch(trainloader_t1)\nprint(\"Visualizing Axial T2 samples\")\nvisualize_batch(trainloader_t2)\nprint(\"Visualizing Sagittal T2/STIR samples\")\nvisualize_batch(trainloader_t2stir)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:11:27.487274Z","iopub.execute_input":"2025-01-05T13:11:27.487798Z","iopub.status.idle":"2025-01-05T13:11:29.454071Z","shell.execute_reply.started":"2025-01-05T13:11:27.487773Z","shell.execute_reply":"2025-01-05T13:11:29.453187Z"},"papermill":{"duration":3.011964,"end_time":"2024-06-06T14:06:46.490657","exception":false,"start_time":"2024-06-06T14:06:43.478693","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimage, label = next(iter(trainloader_t2))\nsample = image[1].permute(1, 2, 0)  #sample\n\n# Plot images\nplt.figsize=(8, 4)\nplt.imshow(images[0], cmap='gray')\nplt.title(label[0])\nplt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:11:32.551964Z","iopub.execute_input":"2025-01-05T13:11:32.552248Z","iopub.status.idle":"2025-01-05T13:11:32.955Z","shell.execute_reply.started":"2025-01-05T13:11:32.552228Z","shell.execute_reply":"2025-01-05T13:11:32.954186Z"},"papermill":{"duration":0.536027,"end_time":"2024-06-06T14:06:47.0795","exception":false,"start_time":"2024-06-06T14:06:46.543473","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model","metadata":{"papermill":{"duration":0.055432,"end_time":"2024-06-06T14:06:47.191138","exception":false,"start_time":"2024-06-06T14:06:47.135706","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"ConvNext","metadata":{"papermill":{"duration":0.053218,"end_time":"2024-06-06T14:06:47.300132","exception":false,"start_time":"2024-06-06T14:06:47.246914","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:11:35.414344Z","iopub.execute_input":"2025-01-05T13:11:35.414646Z","iopub.status.idle":"2025-01-05T13:11:35.46554Z","shell.execute_reply.started":"2025-01-05T13:11:35.414625Z","shell.execute_reply":"2025-01-05T13:11:35.464636Z"},"papermill":{"duration":0.122199,"end_time":"2024-06-06T14:06:47.474804","exception":false,"start_time":"2024-06-06T14:06:47.352605","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomResNet(nn.Module):\n    def __init__(self, num_classes=3, pretrained_weights=None):\n        super(CustomResNet, self).__init__()\n        self.model = models.resnet50(pretrained=False)\n        if pretrained_weights:\n            self.model.load_state_dict(torch.load(pretrained_weights), strict=False)\n        num_ftrs = self.model.fc.in_features\n        self.model.fc = nn.Linear(num_ftrs, num_classes)\n\n    def forward(self, x):\n        return self.model(x)\n\n#self.model.load_state_dict(torch.load(pretrained_weights)) kısmını self.model.load_state_dict(torch.load(pretrained_weights), strict=False) olarak degistirdim","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:15:27.194648Z","iopub.execute_input":"2025-01-05T13:15:27.19497Z","iopub.status.idle":"2025-01-05T13:15:27.199933Z","shell.execute_reply.started":"2025-01-05T13:15:27.194948Z","shell.execute_reply":"2025-01-05T13:15:27.199139Z"},"papermill":{"duration":0.06351,"end_time":"2024-06-06T14:06:47.592218","exception":false,"start_time":"2024-06-06T14:06:47.528708","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Path to the locally uploaded weights file\nweights_path = '/kaggle/input/notebook39b1854952/all_model_weights.pth'\n\n# Initialize models\nsagittal_t1_model = CustomResNet(num_classes=3, pretrained_weights=weights_path).to(device)\naxial_t2_model = CustomResNet(num_classes=3, pretrained_weights=weights_path).to(device)\nsagittal_t2stir_model = CustomResNet(num_classes=3, pretrained_weights=weights_path).to(device)\n\n# Optionally freeze initial layers\nfor param in sagittal_t1_model.model.parameters():\n    param.requires_grad = False\nfor param in axial_t2_model.model.parameters():\n    param.requires_grad = False\nfor param in sagittal_t2stir_model.model.parameters():\n    param.requires_grad = False\n\n# Unfreeze the final fully connected layer\nfor param in sagittal_t1_model.model.fc.parameters():\n    param.requires_grad = True\nfor param in axial_t2_model.model.fc.parameters():\n    param.requires_grad = True\nfor param in sagittal_t2stir_model.model.fc.parameters():\n    param.requires_grad = True\n\n# Training parameters\ncriterion = nn.CrossEntropyLoss()\n\n# Initialize separate optimizers for each model\noptimizer_sagittal_t1 = torch.optim.Adam(sagittal_t1_model.model.fc.parameters(), lr=0.001)\noptimizer_axial_t2 = torch.optim.Adam(axial_t2_model.model.fc.parameters(), lr=0.001)\noptimizer_sagittal_t2stir = torch.optim.Adam(sagittal_t2stir_model.model.fc.parameters(), lr=0.001)\n\n# Store the models and optimizers in dictionaries for easy access\nmodels = {\n    'Sagittal T1': sagittal_t1_model,\n    'Axial T2': axial_t2_model,\n    'Sagittal T2/STIR': sagittal_t2stir_model,\n}\n\noptimizers = {\n    'Sagittal T1': optimizer_sagittal_t1,\n    'Axial T2': optimizer_axial_t2,\n    'Sagittal T2/STIR': optimizer_sagittal_t2stir,\n}","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:15:30.07101Z","iopub.execute_input":"2025-01-05T13:15:30.071352Z","iopub.status.idle":"2025-01-05T13:15:32.079406Z","shell.execute_reply.started":"2025-01-05T13:15:30.071324Z","shell.execute_reply":"2025-01-05T13:15:32.078395Z"},"papermill":{"duration":1.594138,"end_time":"2024-06-06T14:06:49.240234","exception":false,"start_time":"2024-06-06T14:06:47.646096","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count trainable parameters\ntrainable_params = sum(p.numel() for p in sagittal_t1_model.parameters() if p.requires_grad)\nprint(f\"Number of parameters: {trainable_params}\")","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:15:38.298754Z","iopub.execute_input":"2025-01-05T13:15:38.29907Z","iopub.status.idle":"2025-01-05T13:15:38.304713Z","shell.execute_reply.started":"2025-01-05T13:15:38.299044Z","shell.execute_reply":"2025-01-05T13:15:38.303773Z"},"papermill":{"duration":0.063737,"end_time":"2024-06-06T14:06:49.358202","exception":false,"start_time":"2024-06-06T14:06:49.294465","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training","metadata":{"papermill":{"duration":0.053974,"end_time":"2024-06-06T14:06:49.465602","exception":false,"start_time":"2024-06-06T14:06:49.411628","status":"completed"},"tags":[]}},{"cell_type":"code","source":"label_map = {'normal_mild': 0, 'moderate': 1, 'severe': 2}","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:15:41.351828Z","iopub.execute_input":"2025-01-05T13:15:41.352153Z","iopub.status.idle":"2025-01-05T13:15:41.35588Z","shell.execute_reply.started":"2025-01-05T13:15:41.352126Z","shell.execute_reply":"2025-01-05T13:15:41.354956Z"},"papermill":{"duration":0.061535,"end_time":"2024-06-06T14:06:49.580548","exception":false,"start_time":"2024-06-06T14:06:49.519013","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for images, labels in trainloader_t2:\n    labels = torch.tensor([label_map[label] for label in labels])\n    labels = labels.to(device)\n    print(labels)\n    break","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:15:45.729952Z","iopub.execute_input":"2025-01-05T13:15:45.730235Z","iopub.status.idle":"2025-01-05T13:15:46.031661Z","shell.execute_reply.started":"2025-01-05T13:15:45.730214Z","shell.execute_reply":"2025-01-05T13:15:46.030817Z"},"papermill":{"duration":0.257247,"end_time":"2024-06-06T14:06:49.891684","exception":false,"start_time":"2024-06-06T14:06:49.634437","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"##TODO","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:15:49.014495Z","iopub.execute_input":"2025-01-05T13:15:49.014804Z","iopub.status.idle":"2025-01-05T13:15:49.018352Z","shell.execute_reply.started":"2025-01-05T13:15:49.014783Z","shell.execute_reply":"2025-01-05T13:15:49.017388Z"},"papermill":{"duration":0.060637,"end_time":"2024-06-06T14:06:50.007078","exception":false,"start_time":"2024-06-06T14:06:49.946441","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference","metadata":{"papermill":{"duration":0.055543,"end_time":"2024-06-06T14:06:50.116789","exception":false,"start_time":"2024-06-06T14:06:50.061246","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_data['level'].unique()","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:15:51.801192Z","iopub.execute_input":"2025-01-05T13:15:51.801561Z","iopub.status.idle":"2025-01-05T13:15:51.811327Z","shell.execute_reply.started":"2025-01-05T13:15:51.801529Z","shell.execute_reply":"2025-01-05T13:15:51.810365Z"},"papermill":{"duration":0.069661,"end_time":"2024-06-06T14:06:50.242571","exception":false,"start_time":"2024-06-06T14:06:50.17291","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"expanded_test_desc.head(5)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:15:54.180377Z","iopub.execute_input":"2025-01-05T13:15:54.180694Z","iopub.status.idle":"2025-01-05T13:15:54.191318Z","shell.execute_reply.started":"2025-01-05T13:15:54.18067Z","shell.execute_reply":"2025-01-05T13:15:54.190478Z"},"papermill":{"duration":0.068578,"end_time":"2024-06-06T14:06:50.365721","exception":false,"start_time":"2024-06-06T14:06:50.297143","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"levels = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n\n# Function to update row_id with levels\ndef update_row_id(row, levels):\n    level = levels[row.name % len(levels)]\n    return f\"{row['study_id']}_{row['condition']}_{level}\"\n\n# Update row_id in expanded_test_desc to include levels\nexpanded_test_desc['row_id'] = expanded_test_desc.apply(lambda row: update_row_id(row, levels), axis=1)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:15:56.343326Z","iopub.execute_input":"2025-01-05T13:15:56.343651Z","iopub.status.idle":"2025-01-05T13:15:56.350902Z","shell.execute_reply.started":"2025-01-05T13:15:56.343627Z","shell.execute_reply":"2025-01-05T13:15:56.350036Z"},"papermill":{"duration":0.068438,"end_time":"2024-06-06T14:06:50.491276","exception":false,"start_time":"2024-06-06T14:06:50.422838","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"expanded_test_desc.head(2)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:15:58.944044Z","iopub.execute_input":"2025-01-05T13:15:58.944382Z","iopub.status.idle":"2025-01-05T13:15:58.952947Z","shell.execute_reply.started":"2025-01-05T13:15:58.944354Z","shell.execute_reply":"2025-01-05T13:15:58.952088Z"},"papermill":{"duration":0.071322,"end_time":"2024-06-06T14:06:50.618151","exception":false,"start_time":"2024-06-06T14:06:50.546829","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a custom test dataset class\nclass TestDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        image_path = self.dataframe['image_path'][index]\n        image = load_dicom(image_path)  # Define this function to load your DICOM images\n        if self.transform:\n            image = self.transform(image)\n        return image\n\n# Define the transforms\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((224, 224)),\n    transforms.Grayscale(num_output_channels=3),\n    transforms.ToTensor(),\n])\n\n# Create a test dataset and dataloader\ntest_dataset = TestDataset(expanded_test_desc, transform)\ntestloader = DataLoader(test_dataset, batch_size=1, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:16:01.06083Z","iopub.execute_input":"2025-01-05T13:16:01.061111Z","iopub.status.idle":"2025-01-05T13:16:01.067357Z","shell.execute_reply.started":"2025-01-05T13:16:01.061089Z","shell.execute_reply":"2025-01-05T13:16:01.066379Z"},"papermill":{"duration":0.065695,"end_time":"2024-06-06T14:06:50.741277","exception":false,"start_time":"2024-06-06T14:06:50.675582","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for image in testloader:\n    print(image.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:16:04.256227Z","iopub.execute_input":"2025-01-05T13:16:04.256543Z","iopub.status.idle":"2025-01-05T13:16:04.316753Z","shell.execute_reply.started":"2025-01-05T13:16:04.25652Z","shell.execute_reply":"2025-01-05T13:16:04.315821Z"},"papermill":{"duration":0.104233,"end_time":"2024-06-06T14:06:50.902585","exception":false,"start_time":"2024-06-06T14:06:50.798352","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to get the model based on series_description\ndef get_model(series_description):\n    return models.get(series_description, None)\n\n# Function to make predictions on the test data\ndef predict_test_data(testloader, expanded_test_desc):\n    predictions = []\n    normal_mild_probs = []\n    moderate_probs = []\n    severe_probs = []\n    \n    with torch.no_grad():\n        for idx, images in enumerate(tqdm(testloader)):\n            images = images.to(device)\n            series_description = expanded_test_desc.iloc[idx]['series_description']\n            model = get_model(series_description)\n            if model:\n                outputs = model(images)\n                probs = torch.softmax(outputs, dim=1).squeeze(0)\n                normal_mild_probs.append(probs[0].item())\n                moderate_probs.append(probs[1].item())\n                severe_probs.append(probs[2].item())\n                predictions.append(probs)\n            else:\n                normal_mild_probs.append(None)\n                moderate_probs.append(None)\n                severe_probs.append(None)\n                predictions.append(None)\n\n    return normal_mild_probs, moderate_probs, severe_probs, predictions","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:16:06.232768Z","iopub.execute_input":"2025-01-05T13:16:06.233058Z","iopub.status.idle":"2025-01-05T13:16:06.239345Z","shell.execute_reply.started":"2025-01-05T13:16:06.233038Z","shell.execute_reply":"2025-01-05T13:16:06.238394Z"},"papermill":{"duration":0.067733,"end_time":"2024-06-06T14:06:51.027167","exception":false,"start_time":"2024-06-06T14:06:50.959434","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make predictions on the test data\nnormal_mild_probs, moderate_probs, severe_probs, test_predictions = predict_test_data(testloader, expanded_test_desc)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:16:09.058661Z","iopub.execute_input":"2025-01-05T13:16:09.058941Z","iopub.status.idle":"2025-01-05T13:16:15.633752Z","shell.execute_reply.started":"2025-01-05T13:16:09.058922Z","shell.execute_reply":"2025-01-05T13:16:15.632844Z"},"papermill":{"duration":6.501501,"end_time":"2024-06-06T14:06:57.584065","exception":false,"start_time":"2024-06-06T14:06:51.082564","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions[0]","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:16:53.912477Z","iopub.execute_input":"2025-01-05T13:16:53.912748Z","iopub.status.idle":"2025-01-05T13:16:54.111309Z","shell.execute_reply.started":"2025-01-05T13:16:53.912729Z","shell.execute_reply":"2025-01-05T13:16:54.11029Z"},"papermill":{"duration":0.266686,"end_time":"2024-06-06T14:06:57.914753","exception":false,"start_time":"2024-06-06T14:06:57.648067","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add predictions and probabilities to the test DataFrame\nexpanded_test_desc['normal_mild'] = normal_mild_probs\nexpanded_test_desc['moderate'] = moderate_probs\nexpanded_test_desc['severe'] = severe_probs","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:16:57.17794Z","iopub.execute_input":"2025-01-05T13:16:57.178336Z","iopub.status.idle":"2025-01-05T13:16:57.184776Z","shell.execute_reply.started":"2025-01-05T13:16:57.178289Z","shell.execute_reply":"2025-01-05T13:16:57.183945Z"},"papermill":{"duration":0.069554,"end_time":"2024-06-06T14:06:58.043703","exception":false,"start_time":"2024-06-06T14:06:57.974149","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = expanded_test_desc[[\"row_id\",\"normal_mild\",\"moderate\",\"severe\"]]","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:17:00.012495Z","iopub.execute_input":"2025-01-05T13:17:00.012833Z","iopub.status.idle":"2025-01-05T13:17:00.018212Z","shell.execute_reply.started":"2025-01-05T13:17:00.012807Z","shell.execute_reply":"2025-01-05T13:17:00.017092Z"},"papermill":{"duration":0.0714,"end_time":"2024-06-06T14:06:58.17647","exception":false,"start_time":"2024-06-06T14:06:58.10507","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.head(10)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:17:01.587272Z","iopub.execute_input":"2025-01-05T13:17:01.587605Z","iopub.status.idle":"2025-01-05T13:17:01.596915Z","shell.execute_reply.started":"2025-01-05T13:17:01.587582Z","shell.execute_reply":"2025-01-05T13:17:01.596201Z"},"papermill":{"duration":0.076375,"end_time":"2024-06-06T14:06:58.311916","exception":false,"start_time":"2024-06-06T14:06:58.235541","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Group by 'row_id' and sum the values\ngrouped_submission = submission.groupby('row_id').sum().reset_index()\n\n# Normalize the columns\ngrouped_submission[['normal_mild', 'moderate', 'severe']] = grouped_submission[['normal_mild', 'moderate', 'severe']].div(grouped_submission[['normal_mild', 'moderate', 'severe']].sum(axis=1), axis=0)\n\n# Check the first 3 rows\ngrouped_submission.head(3)\n\ngrouped_submission.head(3)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:17:06.026837Z","iopub.execute_input":"2025-01-05T13:17:06.027116Z","iopub.status.idle":"2025-01-05T13:17:06.043452Z","shell.execute_reply.started":"2025-01-05T13:17:06.027096Z","shell.execute_reply":"2025-01-05T13:17:06.042617Z"},"papermill":{"duration":0.084461,"end_time":"2024-06-06T14:06:58.455713","exception":false,"start_time":"2024-06-06T14:06:58.371252","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(grouped_submission)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:17:08.767164Z","iopub.execute_input":"2025-01-05T13:17:08.767513Z","iopub.status.idle":"2025-01-05T13:17:08.772351Z","shell.execute_reply.started":"2025-01-05T13:17:08.767485Z","shell.execute_reply":"2025-01-05T13:17:08.771589Z"},"papermill":{"duration":0.069667,"end_time":"2024-06-06T14:06:58.584984","exception":false,"start_time":"2024-06-06T14:06:58.515317","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the DataFrame to \"submission.csv\" in the desired directory\ngrouped_submission.to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T13:17:11.013591Z","iopub.execute_input":"2025-01-05T13:17:11.013873Z","iopub.status.idle":"2025-01-05T13:17:11.020927Z","shell.execute_reply.started":"2025-01-05T13:17:11.013852Z","shell.execute_reply":"2025-01-05T13:17:11.020218Z"},"papermill":{"duration":0.078885,"end_time":"2024-06-06T14:06:58.723729","exception":false,"start_time":"2024-06-06T14:06:58.644844","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}